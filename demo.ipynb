{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/dongjin/2023/ocr/test.jpg: 480x640 72 Ks, 8 Cs, 4 Js, 5 Es, 103.8ms\n",
      "Speed: 3.3ms preprocess, 103.8ms inference, 34.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mruns/segment/predict\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "수명이\n",
      "다호\n",
      "작동화하는\n",
      "동대지도\n",
      "우주산세요\n",
      "안동임청\n",
      "들어가니까\n",
      "상태로\n",
      "등과\n",
      "안동임대\n",
      "중출을\n",
      "쓰이\n",
      "안동임청\n",
      "작은\n",
      "충렬하여\n",
      "공간으로\n",
      "등이\n",
      "다한\n",
      "공간에\n",
      "올린\n",
      "탐사가\n",
      "우주\n",
      "예상대당도\n",
      "시작된\n",
      "떨어지\n",
      "그런\n",
      "수막은\n",
      "부분으로\n",
      "부분들을\n",
      "않는\n",
      "부분\n",
      "되어\n",
      "안양동에서\n",
      "유발한다\n",
      "등을\n",
      "망원경\n",
      "expres\n",
      "수명이\n",
      "이런\n",
      "우주\n",
      "수명이\n",
      "나온\n",
      "이후에\n",
      "서로\n",
      "말한다\n",
      "statues\n",
      "사고를\n",
      "파편이\n",
      "것으로\n",
      "우주사거리\n",
      "하여\n",
      "junic\n",
      "space\n",
      "안양현초등에\n",
      "정상적으로\n",
      "우주\n",
      "설치한\n",
      "지구에\n",
      "로제\n",
      "끝난\n",
      "있다\n",
      "있을\n",
      "星\n",
      "파편이\n",
      "더\n",
      "이어\n",
      "期\n",
      "空\n",
      "工\n",
      "过\n",
      "立\n",
      "间\n",
      "坡\n",
      "후\n",
      "개\n",
      "큰\n",
      "비교지\n",
      "人形を\n",
      "약\n",
      "手芸\n",
      "現在\n",
      "全弱した\n",
      "크\n",
      "이사상\n",
      "mon\n",
      "본비\n",
      "이\n",
      "이야기\n",
      "이어\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "from PIL import Image\n",
    "import torch\n",
    "\n",
    "torch.cuda.is_available = lambda : False\n",
    "\n",
    "# Image Detection Part\n",
    "model = YOLO(\"./best.pt\")\n",
    "\n",
    "img_path = './test.jpg' # input your image path\n",
    "results = model.predict(img_path, save=True)\n",
    "\n",
    "detection_results = []\n",
    "for result in results:\n",
    "    lang_dict = result.names\n",
    "    for bbox, cls in zip(result.boxes.xyxy, result.boxes.cls):\n",
    "        bbox = bbox.int().tolist()\n",
    "        crop_img = results[0].orig_img[bbox[1]:bbox[3], bbox[0]:bbox[2], :]\n",
    "        detection_results.append((Image.fromarray(crop_img), lang_dict[cls.item()]))\n",
    "\n",
    "# Image Recognition Part\n",
    "import yaml\n",
    "import torchvision.transforms as transforms\n",
    "from models.lightning_model import OcrModel\n",
    "\n",
    "def load_setting(setting):\n",
    "\n",
    "    with open(setting, 'r', encoding='utf8') as f:\n",
    "        cfg = yaml.load(f, Loader=yaml.FullLoader)\n",
    "\n",
    "    return cfg\n",
    "\n",
    "transforms = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize((112,224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ]\n",
    ")\n",
    "\n",
    "cfg = load_setting('Your Setting Path')\n",
    "\n",
    "ocr_model = OcrModel.load_from_checkpoint('Your Checkpoints Path',cfg=cfg, map_location='cpu')\n",
    "\n",
    "ocr_model.eval()\n",
    "ocr_model.decoder_eval()\n",
    "\n",
    "for img, lang in detection_results:\n",
    "    img = transforms(img)\n",
    "    img = img.unsqueeze(0)\n",
    "    print(ocr_model(img, lang))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
